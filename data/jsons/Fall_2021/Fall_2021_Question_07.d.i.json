{
       "Semester": "Fall 2021",
       "Question Number": "7",
       "Part": "d.i",
       "Points": 1.0,
       "Topic": "Neural Networks",
       "Type": "Text",
       "Question": "A neural network is given as Z1 = X * W1, A1 = f1(Z1), Z2 = W2 * A1, \\hat{y} = f2(Z2). We now use back-propagation to update the weights during each iteration. Assume that we only have one data point (X, y) available to use, and the stepsize\nparameter is 0.01. Assume $X = [1, 1, 1, 1]^T, y = [1]$. Further assume that we start with $W^1$ as a matrix of $-1$\u2019s (negative ones) while $W^2$ is a vector of $1$\u2019s (positive ones). How many components of $W^1$ will get updated (i.e. have their value changed) after one iteration of backprop?",
       "Solution": "zero Components"
}