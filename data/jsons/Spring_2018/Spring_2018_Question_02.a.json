{
       "Semester": "Spring 2018",
       "Question Number": "2",
       "Part": "a",
       "Points": 3.0,
       "Topic": "Decision Trees",
       "Type": "Image",
       "Question": "We will continue the example from the previous question.\nFor the dataset indicated below, construct a decision tree (using the algorithm from class, based on weighted entropy) with the original features $x=\\left[x_{1}, x_{2}\\right]^{T}$. Use tests of the form $f<v$. If there is a tie in the choice of split, first prefer $x_{1}$ and then smaller thresholds. You do not need to provide numerical values of the weighted entropy.\nClassic XOR: positive: $(0,1),(1,0)$ and negative: $(0,0),(1,1)$.",
       "Solution": "$\\begin{aligned} \\mathrm{x}_{-} 1 &<0.5 \\\\ \\mathrm{~T}: & \\mathrm{x}_{-} 2<0.5 \\\\ \\mathrm{~T}:-1 \\\\ \\mathrm{~F}:+1 \\\\ \\text { F: } & \\mathrm{x}_{-} 2<0.5 \\\\ \\mathrm{~T}:+1 \\\\ \\text { F: }-1 \\end{aligned}$"
}