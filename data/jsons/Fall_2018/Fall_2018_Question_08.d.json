{
       "Semester": "Fall 2018",
       "Question Number": "8",
       "Part": "d",
       "Points": 4.0,
       "Topic": "Decision Trees",
       "Type": "Text",
       "Question": "There are different strategies for pruning decision trees. We assume that we grow \na decision tree until there is one or a small number of elements in each leaf. Then, we \nprune by deleting individual leaves of the tree until the score of the tree starts to get worse.\nThe question is how to score each possible pruning of the tree.\n Here is a definition of the score: The score is the percentage correct of the tree, computed on the training set, minus a\nconstant C times the number of nodes in the tree. C is chosen in advance by running this algorithm (grow a large tree then prune in order\rto maximize percent correct minus C times number of nodes) for many di\u2000erent values\rof C, and choosing the value of C that minimizes training-set error. Explain whether or not it would be a good \nidea and give a reason why or why not.",
       "Solution": "Not a good idea. Running trials to maximize performance on the training set will not\ngive us an indication of whether this algorithm will produce answers that generalize to\nother data sets."
}